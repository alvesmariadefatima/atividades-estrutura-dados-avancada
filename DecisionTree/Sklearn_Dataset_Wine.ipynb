{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZJVAHCaQaZQ"
      },
      "outputs": [],
      "source": [
        "#import the basic libraries\n",
        "# ReferÃªncia Sklearn Dataset Wine: https://www.kaggle.com/code/cristianlapenta/wine-dataset-sklearn-machine-learning-project/notebook\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#get the wine dataset from sklearn and take a look at the description provided\n",
        "from sklearn import datasets\n",
        "wine = datasets.load_wine()\n",
        "print(wine.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "df['label'] = wine.target\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LTEYiiepQi_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.bincount(df[\"label\"])"
      ],
      "metadata": {
        "id": "GoGRIo1-Qpf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the percentage representation of the classes\n",
        "df.label.value_counts(normalize=True).round(3)"
      ],
      "metadata": {
        "id": "DRR4mu5VQuPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for null/missing values\n",
        "df.info()\n",
        "import missingno as msno\n",
        "msno.bar(df)"
      ],
      "metadata": {
        "id": "BD5JSXBMQwnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(15,10)})\n",
        "sns.heatmap(df.iloc[:,:-1].corr(), annot=True, cmap=\"YlGnBu\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6_9Kzxn_Q4uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df,\n",
        "             hue='label',\n",
        "             palette=\"tab10\",\n",
        "             corner=True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hFcfKoqxRALX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I create X dataframe with features and y with the labels\n",
        "X = df.drop('label', axis=1).values\n",
        "y = df.label.values\n",
        "# I apply feature scaling to the entire dataset in order to apply PCA to display the dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax = MinMaxScaler()\n",
        "X_sc = minmax.fit_transform(X)\n",
        "# I determine percentage of variance for each principal component\n",
        "from sklearn.decomposition import PCA\n",
        "pc_range = np.arange(1,X_sc.shape[1] + 1)\n",
        "pca = PCA(n_components=None)\n",
        "pca.fit(X_sc)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.bar(pc_range, pca.explained_variance_ratio_)\n",
        "plt.step(pc_range, np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xticks(pc_range)\n",
        "plt.xlabel(\"Principal Components\")\n",
        "plt.ylabel(\"Variance\")\n",
        "_ = plt.title(\"Number of Principal Components vs Variance\")\n",
        "\n",
        "print(\"PC\\tvariance\")\n",
        "print(\"---\\t--------\")\n",
        "for i,k in  enumerate(pca.explained_variance_ratio_):\n",
        "    print('PC_{}:\\t{}'.format(i+1, round(k, 3)))"
      ],
      "metadata": {
        "id": "wmAgyD1eRNaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().loc[['min', 'max']].T"
      ],
      "metadata": {
        "id": "37lMCHFqRWvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First of all I divide the dataset into training and testing.\n",
        "#To maintain the class distribution ratio, I assign the labels array to 'stratify'\n",
        "y = df[\"label\"]\n",
        "X = df.iloc[:,:-1]\n",
        "\n",
        "from sklearn.model_selection import train_test_split as split\n",
        "X_train, X_test, y_train, y_test = split(X, y, test_size=0.3, shuffle=True, random_state=0, stratify=y)\n",
        "\n",
        "#scaling the data to equalise min and max of each feature\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# I do the scaler fitting on the training data only\n",
        "#on the training test I do fit and transform simultaneously\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "#now that the scaler has been trained on the training data, I do the transform on the test set\n",
        "#The reason I fit the scaler using only the training data is because I don't want to bias the model with information from the test data.\n",
        "X_test = scaler.transform(X_test)\n",
        "#You should apply fit_transform on the training set and only transform on the validation/test set.\n",
        "#This is done because the validation/test data is meant to emulate data the model has not seen before.\n",
        "#So to fit the validation/test data, we use what was fitted on the training data by using just transform,\n",
        "#which should also be applied to new data that will be fed into the model."
      ],
      "metadata": {
        "id": "3KiYb8b7Re5m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC #model I will train\n",
        "from sklearn.model_selection import StratifiedKFold # for splitting the training-validation data\n",
        "from sklearn.model_selection import GridSearchCV #for validating hyperparameters\n",
        "\n",
        "crossval = StratifiedKFold(n_splits=5, shuffle=True, random_state=0) #choose how many subsets to create\n",
        "\n",
        "#KERNEL: function used to map data into a higher dimension\n",
        "#in SVM+kernel, the idea is to transform the starting space (that of features)\n",
        "#into a more complex one in which there is a hyperplane (hence something linear) separating the data\n",
        "\n",
        "#C: adjusts the amount of errors accepted\n",
        "#for high C the error committed on the training data will weight more in the SVM objective function\n",
        "#the model is then asked to fail less (i.e. to fit the learning data more),\n",
        "#but obtaining a more complex interpolation (= model) interpolation (with the risk, if one exaggerates, of overfitting).\n",
        "#vice versa, if C is low, the model considers less important  the error made on the learning data: the model will be simpler;\n",
        "#if you overdo it, the risk is that of underfitting;\n",
        "#if you think about it, if C is 0 I am ignoring the error I make on the learning data\n",
        "\n",
        "#GAMMA (for RBF kernel): adjusts the curvature of the margins thus limiting the influence of each individual sample\n",
        "#gamma is proportional to the inverse of the standard deviation of the Gaussian\n",
        "#\"fitted\" by the Gaussian kernel to each support vector\n",
        "\n",
        "#DEGREE (for POLY kernel): degree of the polynomial function\n",
        "\n",
        "parameters = [\n",
        "               {\"kernel\": [\"linear\"], \"C\": [0.01, 0.1, 1, 10, 100]},\n",
        "               {\"kernel\": [\"rbf\"], \"C\": [0.01, 0.1, 1, 10, 100], \"gamma\": [0.01, 0.1, 1, 10, 100]},\n",
        "               {\"kernel\": [\"poly\"], \"C\": [0.01, 0.1, 1, 10, 100], \"degree\": np.arange(1,5,1)}\n",
        "              ]\n",
        "\n",
        "model = SVC()\n",
        "clf = GridSearchCV(estimator= model, param_grid=parameters, cv=crossval, verbose=1 , n_jobs=-1)\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Q_rGg5iWRlRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a table with the results of the combinations, sorting them from best to worst:\n",
        "scores = pd.DataFrame(clf.cv_results_)\n",
        "scores = scores.sort_values(by=\"rank_test_score\").set_index(\"rank_test_score\")\n",
        "int_cols = [\"param_C\", \"param_kernel\", \"param_degree\", \"param_gamma\", \"mean_test_score\"]\n",
        "scores[int_cols].head() # only look at the first 5"
      ],
      "metadata": {
        "id": "1FbHL2CvRuyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finally I use the best values of the newly found hyperparameters to train the entire original training set,\n",
        "#evaluating its accuracy on the test set, whose data results as 'unseen'\n",
        "\n",
        "from sklearn.metrics import accuracy_score as accuracy #accuracy metric\n",
        "fitted_model = clf.best_estimator_\n",
        "\n",
        "predictions = fitted_model.predict(X_test)\n",
        "round(accuracy(y_test, predictions), 3) #evaluation"
      ],
      "metadata": {
        "id": "2Q-3UKmpR6yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split as split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score as accuracy\n",
        "\n",
        "#loading the dataset\n",
        "wine = datasets.load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "#separating training and test data\n",
        "X_train, X_test, y_train, y_test = split(X, y, test_size=0.3, shuffle=True, random_state=0, stratify=y)\n",
        "\n",
        "\n",
        "#creating the pipeline containing the scaler, pca and the model\n",
        "pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
        "                 (\"svc\", SVC())])\n",
        "\n",
        "#preparing the values of hyperparameters to be validated\n",
        "parameters = [{\"svc__kernel\": [\"linear\"], \"svc__C\": [0.01, 0.1, 1, 10, 100]},\n",
        "              {\"svc__kernel\": [\"rbf\"], \"svc__C\": [0.01, 0.1, 1, 10, 100], \"svc__gamma\": [0.01, 0.1, 1, 10, 100]},\n",
        "              {\"svc__kernel\": [\"poly\"], \"svc__C\": [0.01, 0.1, 1, 10, 100], \"svc__degree\": np.arange(1,5,1)}]\n",
        "\n",
        "#set the number of subset to be created for validation\n",
        "crossval= StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "#finding the best values to assign to hyperparameters\n",
        "clf = GridSearchCV(pipe, param_grid=parameters, cv=crossval, n_jobs=-1)\n",
        "\n",
        "#training the model with the best hyperparameters found (GridSearchCV applies them automatically)\n",
        "#and I evaluate the accuracy on training and test sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "pred_train = clf.best_estimator_.predict(X_train)\n",
        "pred_test = clf.best_estimator_.predict(X_test)\n",
        "print(f\"Best parameters are: {clf.best_params_}, with a score of {round(clf.best_score_,3)}\")\n",
        "print(f\"Accuracy on training set is: {round(accuracy(y_train, pred_train), 3)}\")\n",
        "print(f\"Accuracy on test set is : {round(accuracy(y_test, pred_test), 3)}\")"
      ],
      "metadata": {
        "id": "dqdIZVV_R_tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, pred_test, labels=[0,1,2]))"
      ],
      "metadata": {
        "id": "Z7bdieAHSHJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(y_test, pred_test, normalize=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xznq9KI0SLdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-plot"
      ],
      "metadata": {
        "id": "1h-oj_21TAm-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}